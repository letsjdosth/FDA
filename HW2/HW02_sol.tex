\documentclass{article}
\usepackage{amsmath,amssymb,setspace,verbatim,graphicx,enumerate,enumitem}
\usepackage[top=1in,bottom=1in,left=1in,right=1in,nohead,nofoot]{geometry}
\usepackage{caption}
\usepackage{mathtools}
% \usepackage{subcaption}
% \usepackage{subfig}
% \usepackage{subfloat}
% \usepackage{tabularx}
\usepackage{mdframed}

\newenvironment{Rcode}% environment name 
{%begin code
    \begin{mdframed}
    \#R code
    \begin{small}
}
{%end code
    \end{small}
    \end{mdframed}
}

\newenvironment{console}% environment name 
{%begin code
    \begin{mdframed}
    \#Console
    \begin{small}
}
{%end code
    \end{small}
    \end{mdframed}
}

\begin{document}
\title{FDA Homework 2}
\author{Seokjun Choi}
\date{October 18, 2019}
\maketitle

\section{Chapter 10}
\subsection{Problem 2}

\textbf{
Show that in any inner product space, the function $y\rightarrow<x,y>$ is continuous where x is arbitary element of that inner product space.
}

Let $\mathcal{H}$ be an inner product space, \(\{f_n\}\) be a sequence in $\mathcal{H}$
such that converges to $f\in\mathcal{H}$ in norm sense. \\
For $x\in\mathcal{H}$, consider below relation.
\[|<x, f_n>-<x,f>|^2 = |<x, f_n-f>|^2 \leq ||x||^2||f_n-f||^2\]
Last inequality comse from Cauchy-Schwartz inequality. Then when $n\rightarrow\infty$, by our setting $||f_n-f||\rightarrow0$, so
\[lim_{n\rightarrow\infty}|<x, f_n>-<x,f>|^2\leq 0\]
Then, since square term has always nonnegative value,
\[lim_{n\rightarrow\infty}<x, f_n>-<x,f>= 0\]
Thus \(lim_{n\rightarrow\infty}<x, f_n> = <x,f>\). From this, we show that the inner product operator preserves the limit.
It is equivalent statement to that inner product operator is continuous.


\subsection{Problem 6}
\textbf{
    Suppose $\{e_j,j\geq 1\}$ is a complete orthonormal sequence in a Hilbert space. 
    Show that if $\{f_j,j\geq 1\}$ is an orthonormal sequence satisfying
    \[\sum_{j=1}^\infty ||e_j-f_j||^2<1\]
    then $\{f_j,j\geq 1\}$ is also complete.
}

Firstly, I claim that $e_j$ and $f_j$ are not orthorgonal. \\
Consider a simple case that only one component of fixed $j$ index is different $e_j$ from $f_j$. then,
If $e_j, f_j$ are orthogonal, by the Pythagorean theorem, $||e_j-f_j||^2=||e_j||^2+||f_j||^2=1+1=2$
since $e_j$ and $f_j$ are unit elements. But under our assumption, $||e_j-f_j||^2$ cannot reach the value 2.

More formally,
\[||e_j-f_j||^2=<e_j-f_j, e_j-f_j>=<e_j, e_j>-<e_j,f_j>-<f_j,e_j>+<f_j,f_j>\]
\[=||e_j||^2+||f_j||^2-(<e_j,f_j>+<f_j,e_j>) = 2-(<e_j,f_j>+<f_j,e_j>) < 1\]
so
\[<e_j,f_j>+<f_j,e_j>=<e_j,f_j>+\overline{<e_j,f_j>}=2Re(<e_j,f_j>)\] cannot become 0,
neither can $<e_j,f_j>$, so they are not orthogonal. Thus the claim is proved for simple case.

Next, consider many j-th components are different $e_j$ from $f_j$. But above claim still holds, because
\(\sum_{j=1}^\infty ||e_j-f_j||^2<1\) and all norm values must be nonnegative,
none of j-th component of $||e_j-f_j||$ can be greater then 1 like the simple cases. 
It means that $<e_j,f_j>+<f_j,e_j>=2Re(<e_j,f_j>)$ cannot be 0 for all $j$.
So above claim is proved for whole cases.


Then as what we get from above claim, if we express $f_j$ as the linear combination of $\{e_i\}$, 
$f_j$ always has $e_j$ component term with nonzero coefficient.
(More precisely, use Gram-Schmidt process, or just project $f_j$ onto $e_j$ orthogonally.
Then because $f_j$ is not orthogonal to $e_j$,
we get $e_j$ component term of nonzero coefficient in $f_j$'s expression of linear combination using $\{e_i\}$.)

So, if we express whole space $\mathcal{H}$ as \(\mathcal{H}=span\{e_1,e_2,...,e_j,...\}\), then
we can also re-express $\mathcal{H}$ as \(\mathcal{H}=span\{e_1,e_2,...,f_j,...\}\).
Then for each $j$, we replace $e_j$ to $f_j$ inductively from $j=1$ to $\infty$ for above span expression.
Then as a result we get \(\mathcal{H}=span\{f_1,f_2,...,f_j,...\}\) for $\{f_j, j\geq 1\}$, it's what we want.




\subsection{Problem 10}
\textbf{
    Suppose $\{e_j,j>=1\}$ and $\{f_i,i>=1\}$ are orthonormal bases in $\mathcal{H}$.
    Show that for any Hilbert-Schmidt operators $\Psi,\Phi$
    \[\sum_{i=1}^{\infty} <\Psi(f_i), \Phi(f_i)> = \sum_{j=1}^{\infty} <\Psi(e_j),\Phi(e_j)>\]
}

Firstly note that $f_i=\sum_{j=1}^\infty<f_i,e_j>e_j$, 
and since $\Phi$ are Hilbert-Schmidt, there exists adjoint operator  $\Phi^*$.
Using these facts,
\[\sum_{i=1}^{\infty} <\Psi(f_i), \Phi(f_i)>
= \sum_{i=1}^{\infty} <\Phi^*\Psi(f_i), f_i> 
= \sum_{i=1}^\infty <\Phi^*\Psi\sum_{j=1}^\infty <f_i,e_j>e_j, \sum_{k=1}^\infty <f_i,e_k>e_j>\]
then
\[=\sum _{i=1}\sum_{j=1}\sum_{k=1}<f_i,e_j>\overline{<f_i,e_k>}<\Phi^*\Psi(e_j),e_k>
=\sum _{i=1}\sum_{j=1}\sum_{k=1}<f_i,e_j><e_k,f_i><\Phi^*\Psi(e_j),e_k>\]
Since the operator $\Phi^*\Psi$ is also Hilbert-Schmidt, the value of absolute summation
\(\sum _{i=1}\sum_{j=1}\sum_{k=1}|<f_i,e_j><e_k,f_i><\Phi^*\Psi(e_j),e_k>|<\infty\)
and we can interchange the summation order. then
\[=\sum_{j=1}\sum_{k=1}<\Phi^*\Psi(e_j),e_j>(\sum_{i=1}<f_i,e_j><e_k,f_i>)\]
If we think the linear operator $L:\mathcal{H}\rightarrow\mathcal{H}$ such that
maps each $f_i$ to $e_i$, then since both $\{f_i\}, \{e_i\}$ are orthonormal, 
$LL^*=L^*L$ is identity operator.
It means that, for $j\neq k$, the last summation's term (with $i$) becomes 0,
and for only $j=k$ cases remain with value 1 because of using orthonormal set.

So we rewrite above equation (with $j=k$, using only 1 summation symbol) as
\[=\sum_{j=1} <\Phi^*\Psi(e_j),e_j>
=\sum_{j=1} <\Psi(e_j),\Phi(e_j)>\]
from the assumption that $\{f_i\}$ is in orthornormal set.




\subsection{Problem 12}
\textbf{
    Show that if $L$ is bounded then $L^*$ is also bounded, and
    \[||L^*||_{\mathcal{L}}=||L||_{\mathcal{L}}, \quad  
    ||L^*L||_{\mathcal{L}}=||L||^2_{\mathcal{L}}
    \]
}

Firstly, I construct a lemma.
\[||L||_{\mathcal{L}} = \sup\{|<Lx,y>|:||x||\leq 1, ||y||\leq 1\}\]
For proof of the lemma, (1) $\geq$ direction is simple consquence of Cauchy-Schwartz inequality.
\(|<Lx,y>|\leq ||Lx||||y|| \leq ||Lx||\) for $||x||\leq 1$. Take supremum(within $||x||\leq 1$) both side.
(2) To get $\leq$ direction, for $x\in \mathcal{H} \text{ s.t.} ||x||\leq 1$,
let $x'=x/||x||, y'=Lx/||Lx||$. Then if $\sup|<Lx,y>|= M$ for some $M\in\mathcal{R}$, then $|<Lx',y'>|\leq M$ by assumption, and observe that
\(|<Lx',y'>|=|<\frac{Lx}{||x||},\frac{Lx}{||Lx||}>=\frac{||Lx||^2}{||x||||Lx||}=\frac{||Lx||}{||x||}\), so
$||Lx||\leq M||x||$. Take supremum(within $||x||\leq 1$) both side. Note that the argument which gives supremum value always satisfies $||x||=1$.

Let's start our main goal.

For boundedness and first identity, consider
\[||L||_\mathcal{{L}}=\sup\{|<Lx, y>| :||x||\leq 1, ||y||\leq 1\}\]
\[=\sup\{|<x, L^*y>| :||x||\leq 1, ||y||\leq 1\} = ||L^*||\]
So if $L$ is bounded($||L||_\mathcal{L}<\infty$), then $L^*$ is also bounded($||L^*||_\mathcal{L}<\infty$).

For second identity, 
let $x\in \mathcal{H} \text{ such that } ||x||\leq 1$, be argument of realizing supremum of definition of operator norm, \(||L||_{L}=||Lx||\).
then consider
\[||L||_\mathcal{{L}}=\sup\{|<Lx/||Lx||, Ly>| : ||y||\leq 1\}\]
\[=\sup\{|\frac{<x, L^*Ly>}{{||Lx||}}| : ||y||\leq 1\}\]
\[=\frac{1}{||L||_{\mathcal{L}}}\sup\{|<x, L^*Ly>| : ||y||\leq 1\}=\frac{||L^*L||_{\mathcal{L}}}{||L||_{\mathcal{L}}}\]
Note that, by our assumption over $x$, the supremum would be realized at $y=x$. So if $||x||\leq1$ is omitted on condition of supremum like above expression, it does not become problem.

Then, Multiply $||L||_{\mathcal{L}}$ both side.

\newpage
\section{Chapter 11}
\subsection{Problem 5}
\textbf{
    Suppose for each $k=1,2,...,M$, $Y_{k,n}, Y_k$ are random variables such that for every $M\geq 1$,
    \[ [Y_{1,n},Y_{2,n},...,Y_{M,n}]^T\xrightarrow{d} [Y_1,Y_2,...,Y_M]^T\]
    in the Euclidean space $\mathcal{R}^M$. Suppose $\{w_k, k\geq 1\}$ is a sequence of numbers such that
    \[\sum_{k=1}^{\infty}|w_k| E(|Y_k|)<\infty \text{ and } \sum_{k=1}^{\infty}|w_k|\sup_{n\geq 1}E|Y_{k,n}-Y_k|<\infty\]
    Using Theorem 11.1.3, show that \(\sum_{k=1}^{\infty}w_kY_{k,n}\xrightarrow{d}\sum_{k=1}^{\infty}w_kY_k\).
}

To overview my procedure solving this problem easier to reader, especially the form of using the theorem 11.1.3, 
I will start to match our case to the notation of the theorem's assumption on the book. \\
our case $\leftrightarrow$ theorem11.1.3 \\
\(\sum_{k=1}^{u}w_kY_{k,n} \leftrightarrow X_n(u) \) \\
\(\sum_{k=1}^{u}w_kY_{k} \leftrightarrow X(u) \) \\
\(\sum_{k=1}^{\infty}w_kY_{k,n} \leftrightarrow X_n \) \\
\(\sum_{k=1}^{\infty}w_kY_{k} \leftrightarrow X \) \\

More formally, since \([Y_{1,n},Y_{2,n},...,Y_{M,n}]^T\xrightarrow{d} [Y_1,Y_2,...,Y_M]^T\) for every $M\geq1$ and
$\{w_k\}$ are just real number,
if I momently fix $M$ as $u$, I can get a condition that \(\sum_{k=1}^{u}w_kY_{k,n}\xrightarrow{d}\sum_{k=1}^{u}w_kY_{k}\).
and by letting $u$ increase to $\infty$, also can get 
\(\sum_{k=1}^{u}w_kY_{k}\xrightarrow{d}\sum_{k=1}^{\infty}w_kY_{k}\).
Note that the last term's convergence is guaranteed by our problem's assumption, \(\sum_{k=1}^{\infty}|w_k| E(|Y_k|)<\infty\).
Nextly, from our problem's another assumption $\sum_{k=1}^{\infty}|w_k|\sup_{n\geq 1}E|Y_{k,n}-Y_k|<\infty$,
\[\sup_{n\geq 1}E|w_kY_{k,n}-w_kY_k|\rightarrow0 \text{ as } k\rightarrow\infty \]
Since it converges to the constant, it directly implies some analogues without E - in this case a thing of integral operator - and with measure sense.
If I write concretely,
\[\lim_{u\rightarrow\infty}\limsup_{n\rightarrow\infty}P(d(\sum_{k=1}^{u}w_kY_{k,n},\sum_{k=1}^{\infty}w_kY_{k,n})>\epsilon)=0\]
So theorem 11.1.3's condition are all set. Let's apply the theorem! Then we get
\(\sum_{k=1}^{\infty}w_kY_{k,n}\xrightarrow{d}\sum_{k=1}^{\infty}w_kY_k\).

\subsection{Problem 9}
\textbf{
    Suppose $\mathcal{H}$ is an infinite dimensional separable Hilbert space and $\{e_j,j\geq1\}$ is an orthonormal system.
    Define the operator $\Psi$ by
    \[\Psi(x)=\sum_{j=1}^{\infty}j^{-1}<x,e_j>e_j\]
    Show that $\Psi$ is bounded, symmetric and nonnegative definite, but it is not a covariance operator.
}

Boundness is straightforward. To reach the supremum of a definition of operator norm(of $\mathcal{H}$),
we should choose simply $e_1$ because $j^{-1}$ decreases as $j$ goes to $\infty$.
And we can get $||\Psi||=1<\infty$ incidently from the form of $\Psi$.

Next, since $\Psi$ is clearly linear and bounded as we showed, there exists an adjoint $||\Psi^*||$.
Then, with the fact that $j$ has no imaginary part,
\[<\Psi(x),y>=<\sum_{j=1}^{\infty}j^{-1}<x,e_j>e_j,y>
=\sum_{j=1}^{\infty}j^{-1}<<x,e_j>e_j,<y,e_j>e_j>\]
\[=\sum_{j=1}^{\infty}<<x,e_j>e_j,j^{-1}<y,e_j>e_j>
=\sum_{j=1}^{\infty}<x,j^{-1}<y,e_j>e_j>
=\sum_{j=1}^{\infty}<x,\Psi(y)>\]
So $\Psi=\Psi^*$, and it means that $\Psi$ is symmetric operator.

To show $\Psi$ is nonnegative,
\[<\Psi(x),x>=\sum_{j=1}^{\infty}j^{-1}<<x,e_j>e_j,x>\]
and just note that $j^{-1}>0, <x,x>\geq0$ for all $x$. (In fact, positive operator is also symmetric in Hilbert space.)

But, $\Psi$ is not Hilbert-Schmidt, nor covariance operator. For seeing the reason, consider below.

Since $\Psi$ is symmetric, we can apply spectral theorem to $\Psi$.
For simplicity for our discussion, Without loss of generality(because Hilbert-Schmidt norm is basis-invariant) 
choose the original basis of $\mathcal{H}, \{e_j\}$ to coincide to eigenvector(or eigenfunctions, etc. corresponded some eigen-element type consisting $\mathcal{H}$) of $\Psi$.
then, naturally $\{j^{-1}\}$ become eigenvalues. And if we denote the set of Hilbert-Schmidt operator on $\mathcal{H}$ as $\mathcal{S}$,
\[||\Psi||_{\mathcal{S}}^{2}=\sum_{j=1}^{\infty}(j^{-1})^2=\infty\]
so $\Psi\notin\mathcal{S}$.



\subsection{Problem 14}
\textbf{
    Suppose X satisfies Definition 11.3.2 and let L be a bounded operator. 
    Show that $L(X)$ is Gausian; find its expected value and covariance operator.
}

Maybe in the problem, a condition $L$ is linear map from $\mathcal{H}$ to $\mathcal{H}$' is missed. I'll assume it.

Firstly, since $L$ is bounded linear operator, there exists an adjoint operator $L^*$.
Then, let's consider the characteristic functional of $L(X)$. 
For $y\in\mathcal{H}$,
\[\phi_{L(X)}(y)=Eexp\{i<y,LX>\}=Eexp\{i<L^*y,X>\}=\phi_X(L^*y)\]
Then, since $X$ follows Gaussian by assumption(definition 11.3.2),
\[\phi_{L(X)}(y)=\phi_X(L^*y)=exp\{i<\mu,L^*y>-\frac{1}{2}<C(L^*y),L^*y>\}
=exp\{i<L\mu,y>-\frac{1}{2}<LC(L^*y),y>\}\]
From above form of characteristic functional of $L(X)$, we can observe that $L(X)$ follows Gaussian again, with
mean function $L\mu$, covariance operator $LCL^*$.


\end{document}

